{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to translate the csv file to json format and create a temporary .json file\n",
    "#and create an initial DataFrame object\n",
    "def data_read_inventory():\n",
    "    with open (\"Inventroy.csv\", \"r\") as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    with open(\"temporary_Inventory_json.json\",\"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "        \n",
    "    df = pd.read_csv('Inventroy.csv')    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to translate the csv file to json format and create a temporary .json file\n",
    "#and create an initial DataFrame object\n",
    "def data_read_inspections():\n",
    "    with open (\"Inspections.csv\", \"r\") as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    with open(\"temporary_Inspections_json.json\",\"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    \n",
    "    df = pd.read_csv('Inspections.csv')   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to translate the csv file to json format and create a temporary .json file\n",
    "#and create an initial DataFrame object\n",
    "def data_read_violations():\n",
    "    with open (\"violations.csv\", \"r\") as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    with open(\"temporary_Violations_json.json\",\"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    \n",
    "    df = pd.read_csv('violations.csv')    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean_inventory(df):\n",
    "    \n",
    "    #Column names cleaning\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\\\n",
    ".str.replace('(', '').str.replace(')', '')\n",
    "    \n",
    "    df.rename(columns={'facility__state': 'facility_state'}, inplace=True)\n",
    "    \n",
    "    #Creating new column named \"seating_number_and_type\"\n",
    "    df.insert(6, \"seating_number_type\", True)\n",
    "    \n",
    "    #Using a regex to extract the information to the new column\n",
    "    df['seating_number_type'] = df.pe_description.str.extract(r'(\\([^)]*\\))',  \n",
    "                                     expand = True)\n",
    "    df['pe_description'] = df.pe_description.str.replace(r'(\\([^)]*\\))', '')\n",
    "    df['pe_description'] = df.pe_description.str.replace(r'  ', ' ')\n",
    "    \n",
    "    #Cleaning the states columns (facility_state , owner_state)\n",
    "    df['facility_state'] = df.facility_state.str.replace(r'`', 'CA')\n",
    "    df['owner_state'] = df.owner_state.str.replace(r'`', 'NO STATE GIVEN')\n",
    "    \n",
    "    #Replace all multiple spaces with single\n",
    "    df = df.replace(['      '], ' ', regex = True)\n",
    "    df = df.replace(['     '], ' ', regex = True)\n",
    "    df = df.replace(['    '], ' ', regex = True)\n",
    "    df = df.replace(['   '], ' ', regex = True)\n",
    "    df = df.replace(['  '], ' ', regex = True)\n",
    "    \n",
    "    #Replace unicode or special characters\n",
    "    df = df.replace([\"&#160;\"],\" \", regex = True)\n",
    "    df = df.replace([\"‚Äô\"],\"'\", regex = True)\n",
    "    df = df.replace([\"√ë\"],\"Ñ\", regex = True) \n",
    "    df = df.replace([\"‚Ä∫\"],\"\", regex = True)\n",
    "    df = df.replace([\"√â\"],\"É\", regex = True)\n",
    "    df = df.replace([\"¬¢\"],\"\", regex = True)\n",
    "    df = df.replace([\"85*C\"],\"85C\", regex = True)\n",
    "    df = df.replace([\"85 C\"],\"85C\", regex = True)\n",
    "    df = df.replace([\"¬∞ \"],\"\", regex = True)\n",
    "    \n",
    "    df = df.replace([\"CAPRIOTI\"],\"CAPRIOTTI\", regex = True)\n",
    "    \n",
    "    #Replace semicolon with apostrophe\n",
    "    df = df.replace([';'], \"'\", regex = True)\n",
    "    \n",
    "    #Drop the program_name column as it duplicates the data with facility_name column. \n",
    "    df.drop('program_name', inplace=True, axis=1)\n",
    "    \n",
    "    #Drop facility_latitude and facility_longitude as they duplicate information from location column\n",
    "    df.drop('facility_latitude', inplace=True, axis=1)\n",
    "    df.drop('facility_longitude', inplace=True, axis=1)        \n",
    "    \n",
    "    #Capitalise columns to keep consistent uppercase naming\n",
    "    df['facility_address'] = df['facility_address'].str.upper()\n",
    "    df['facility_city'] = df['facility_city'].str.upper()\n",
    "    df['facility_state'] = df['facility_state'].str.upper()\n",
    "    df['owner_name'] = df['owner_name'].str.upper()\n",
    "    df['owner_address'] = df['owner_address'].str.upper()\n",
    "    df['owner_city'] = df['owner_city'].str.upper()\n",
    "    df['owner_state'] = df['owner_state'].str.upper()\n",
    "    \n",
    "    #Convert float values to integer in specific columns and fill missing values with 0\n",
    "    \n",
    "    df['census_tracts_2010'] = df['census_tracts_2010'].fillna(0.0).astype(np.int64)\n",
    "    df['census_tracts_2010'] = df['census_tracts_2010'].astype(np.int64)\n",
    "    \n",
    "    df['2011_supervisorial_district_boundaries_official'] = df['2011_supervisorial\\\n",
    "_district_boundaries_official'].fillna(0.0).astype(np.int64)\n",
    "    df['2011_supervisorial_district_boundaries_official'] = df['2011_supervisorial\\\n",
    "_district_boundaries_official'].astype(np.int64)\n",
    "    \n",
    "    df['board_approved_statistical_areas'] = df['board_approved_statistical_areas'].fillna(0.0).astype(np.int64)\n",
    "    df['board_approved_statistical_areas'] = df['board_approved_statistical_areas'].astype(np.int64)\n",
    "\n",
    "    df['zip_codes'] = df['zip_codes'].fillna(0.0).astype(np.int64)\n",
    "    df['zip_codes'] = df['zip_codes'].astype(np.int64)\n",
    "    \n",
    "    #Filling NaN values \n",
    "    df['owner_city'] = df['owner_city'].fillna(\"NO CITY GIVEN\")\n",
    "    df['owner_state'] = df['owner_state'].fillna(\"NO STATE GIVEN\")\n",
    "    df['owner_zip'] = df['owner_zip'].fillna(\"NO ZIP CODE GIVEN\")\n",
    "    df['location'] = df['location'].fillna(\"NO LOCATION\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean_inspections(df):\n",
    "    #Column names cleaning\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\\\n",
    ".str.replace('(', '').str.replace(')', '')\n",
    "    \n",
    "    #Creating new column named \"seating_number_and_type\"\n",
    "    df.insert(11, \"seating_number_type\", True)\n",
    "    \n",
    "    #Using a regex to extract the information to the new column\n",
    "    df['seating_number_type'] = df.pe_description.str.extract(r'(\\([^)]*\\))',  \n",
    "                                     expand = True)\n",
    "    df['pe_description'] = df.pe_description.str.replace(r'(\\([^)]*\\))', '')\n",
    "    df['pe_description'] = df.pe_description.str.replace(r'  ', ' ')\n",
    "    \n",
    "    #Cleaning the facility_state column\n",
    "    df['facility_state'] = df.facility_state.str.replace(r'`', 'CA')\n",
    "    \n",
    "    #Strip word \"point\" from location column\n",
    "    df['location'] = df.location.str.replace(r'(POINT)', '', regex=True)\n",
    "    \n",
    "    #Replace all multiple spaces with single\n",
    "    df = df.replace(['      '], ' ', regex = True)\n",
    "    df = df.replace(['     '], ' ', regex = True)\n",
    "    df = df.replace(['    '], ' ', regex = True)\n",
    "    df = df.replace(['   '], ' ', regex = True)\n",
    "    df = df.replace(['  '], ' ', regex = True)\n",
    "    \n",
    "    #Replace unicode or special characters\n",
    "    df = df.replace([\"&#160;\"],\" \", regex = True)\n",
    "    df = df.replace([\"‚Äô\"],\"'\", regex = True)\n",
    "    df = df.replace([\"√ë\"],\"Ñ\", regex = True) \n",
    "    df = df.replace([\"‚Ä∫\"],\"\", regex = True)\n",
    "    df = df.replace([\"√â\"],\"É\", regex = True)\n",
    "    df = df.replace([\"¬¢\"],\"\", regex = True)\n",
    "    df = df.replace([\"85*C\"],\"85C\", regex = True)\n",
    "    df = df.replace([\"85 C\"],\"85C\", regex = True)\n",
    "    df = df.replace([\"¬∞ \"],\"\", regex = True)\n",
    "    \n",
    "    df = df.replace([\"CAPRIOTI\"],\"CAPRIOTTI\", regex = True)\n",
    "    \n",
    "    #Replace semicolon with apostrophe\n",
    "    df = df.replace([';'], \"'\", regex = True)\n",
    "    \n",
    "    #Drop the program_name column as it duplicates the data with facility_name column    \n",
    "    df.drop('program_name', inplace=True, axis=1)\n",
    "    \n",
    "    #Capitalise columns to keep consistent uppercase naming\n",
    "    df['owner_name'] = df['owner_name'].str.upper()\n",
    "    df['facility_name'] = df['facility_name'].str.upper()\n",
    "    df['facility_state'] = df['facility_state'].str.upper()\n",
    "    df['facility_address'] = df['facility_address'].str.upper()\n",
    "    df['facility_city'] = df['facility_city'].str.upper()\n",
    "    df['facility_state'] = df['facility_state'].str.upper()\n",
    "    \n",
    "    #Convert float values to integer in specific columns and fill missing values with 0 \n",
    "    df['score'] = df['score'].fillna(0.0).astype(np.int64)\n",
    "    df['score'] = df['score'].astype(np.int64)\n",
    "    \n",
    "    df['census_tracts_2010'] = df['census_tracts_2010'].fillna(0.0).astype(np.int64)\n",
    "    df['census_tracts_2010'] = df['census_tracts_2010'].astype(np.int64)\n",
    "    \n",
    "    df['2011_supervisorial_district_boundaries_official'] = df['2011_supervisorial\\\n",
    "_district_boundaries_official'].fillna(0.0).astype(np.int64)\n",
    "    df['2011_supervisorial_district_boundaries_official'] = df['2011_supervisorial\\\n",
    "_district_boundaries_official'].astype(np.int64)\n",
    "    \n",
    "    df['board_approved_statistical_areas'] = df['board_approved_statistical_areas'].fillna(0.0).astype(np.int64)\n",
    "    df['board_approved_statistical_areas'] = df['board_approved_statistical_areas'].astype(np.int64)\n",
    "\n",
    "    df['zip_codes'] = df['zip_codes'].fillna(0.0).astype(np.int64)\n",
    "    df['zip_codes'] = df['zip_codes'].astype(np.int64)\n",
    "    \n",
    "    #Filling NaN values \n",
    "    df['seating_number_type'] = df['seating_number_type'].fillna(\"PRIVATE\")\n",
    "    df['grade'] = df['grade'].fillna(\"NO GRADE GIVEN\")\n",
    "    df['location'] = df['location'].fillna(\"NO LOCATION GIVEN\")\n",
    "    \n",
    "    #Replacing the seating_number_type column values to more descriptive names\n",
    "    replace_values = {'(0-10)':'(0-10 SEATS)', '(0-1999 SF)':'(0-1999 SQUARE FEET)', '(0-30)':'(0-30 SEATS)',\n",
    "                  '(0-999 SQ. FT.)':'(0-999 SQUARE FEET)', '(1,000-1,999 SQ. FT.)':'(1,000-1,999 SQUARE FEET)',\n",
    "                  '(1-1,999 SF)':'(1-1,999 SQUARE FEET)','(1-1,999 SQ. FT.)':'(1-1,999 SQUARE FEET)',\n",
    "                  '(1-1,999)':'(1-1,999 SEATS)', '(1-4,999)':'(1-4,999 SEATS)', '(10,000+ SF)':'(10,000+ SQUARE FEET)',\n",
    "                  '(151 + )':'(151+ SEATS)', '(2,000+ SF)':'(2,000+ SQUARE FEET)', '(2,000-4,999)':'(2,000-4,999 SEATS)',\n",
    "                  '(2,000-5,999 SF)':'(2,000-5,999 SQUARE FEET)', '(2000-3999 SF)':'(2000-3999 SQUARE FEET)',\n",
    "                  '(31-60)':'(31-60 SEATS)', '(4000-9999 SF)':'(4000-9999 SQUARE FEET)',\n",
    "                  '(5,000 + )':'(5,000+ SEATS)', '(61-150)':'(61-150 SEATS)'}\n",
    "    \n",
    "    df = df.replace({\"seating_number_type\": replace_values})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean_violations(df):\n",
    "    #Column names cleaning\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\\\n",
    ".str.replace('(', '').str.replace(')', '')\n",
    "    \n",
    "    df.rename(columns={'violation__status': 'violation_status'}, inplace=True)\n",
    "    \n",
    "    #Remove duplicates from violation_code and violation_description columns\n",
    "    \n",
    "    #Strip numerical values out of violation_description column so the violation_code \n",
    "    #corresponds to each violation_description value\n",
    "    pattern = '[0-9]'\n",
    "    df['violation_description'] = df['violation_description'].str.replace(pattern,'')\n",
    "    \n",
    "    df['violation_description'] = df['violation_description'].str.replace('# . ','')\n",
    "    df['violation_description'] = df['violation_description'].str.replace('# a. ','')\n",
    "    df['violation_description'] = df['violation_description'].str.replace('# b. ','')\n",
    "    df['violation_description'] = df['violation_description'].str.replace('.','')\n",
    "    df['violation_description'] = df['violation_description'].str.replace('  ',' ')\n",
    "    \n",
    "    df['violation_description'] = df['violation_description'].str.replace('Equipment/utensils \\\n",
    "approved;','Equipment/Utensils - approved;')\n",
    "    \n",
    "    #Remove duplicate violation_code values so each violation_code corresponds to each violation_description value   \n",
    "    replace_values = {'MF08':'F007', 'MF15':'F014', 'MF31':'F030', 'MF34':'F033', 'MF36':'F035', 'MF38':'F037',\n",
    "                     'MF45':'F044', 'F055':'F001', 'F056':'F010', 'F057':'F018', 'F058':'F019', 'W001':'F007', 'W048':'F048'}\n",
    "    \n",
    "    df = df.replace({\"violation_code\": replace_values})\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
